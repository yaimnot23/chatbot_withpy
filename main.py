import os
import sys
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_chroma import Chroma
from langchain_classic.chains import create_retrieval_chain
from langchain_classic.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate

# 1. í™˜ê²½ì„¤ì • ë¡œë“œ(envì—ì„œ)
load_dotenv()

def start_chatbot():
    # API í‚¤ í™•ì¸
    if not os.getenv("GOOGLE_API_KEY"):
        print("âŒ .env íŒŒì¼ì— GOOGLE_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit()

    # 2. DB ë° ëŒ€í•™êµ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
    db_path = "./db"
    if not os.path.exists(db_path):
        print(f"âŒ '{db_path}' í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤. 'python ingest.py'ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ì¸ë±ì‹±í•´ì£¼ì„¸ìš”!")
        sys.exit()

    print("ğŸ” ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
    try:
        # ì„ë² ë”© ëª¨ë¸ ì„¤ì •
        embeddings = GoogleGenerativeAIEmbeddings(model="text-embedding-004")
        
        # ë²¡í„° DB ë¡œë“œ
        vectorstore = Chroma(
            persist_directory=db_path,
            embedding_function=embeddings
        )

        # ì „ì²´ ëŒ€í•™ ëª©ë¡ ì¶”ì¶œ (ë©”íƒ€ë°ì´í„°ì—ì„œ ê³ ìœ ê°’ ê°€ì ¸ì˜¤ê¸°)
        # ê²€ìƒ‰ ì •í™•ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ ë¯¸ë¦¬ ëŒ€í•™ ëª©ë¡ì„ ì•Œê³  ìˆìœ¼ë©´ ì¢‹ìŠµë‹ˆë‹¤.
        print("ğŸ“ ëŒ€í•™êµ ëª©ë¡ ë¡œë”© ì¤‘...")
        all_metas = vectorstore.get().get('metadatas', [])
        univ_list = sorted(list(set([m.get('univ') for m in all_metas if m.get('univ')])))
        print(f"âœ… {len(univ_list)}ê°œì˜ ëŒ€í•™êµ ì •ë³´ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤.")

        # 3. ì±—ë´‡ ì„¤ì • (Retriever & LLM)
        # ê²€ìƒ‰ í’ˆì§ˆì„ ë†’ì´ê¸° ìœ„í•´ MMR(Maximal Marginal Relevance) ê²€ìƒ‰ë°©ì‹ ì‚¬ìš©
        # 100ê°œë¥¼ ë¨¼ì € ë½‘ì€ ë’¤, ê·¸ ì¤‘ ê°€ì¥ ì˜ë¯¸ê°€ ê²¹ì¹˜ì§€ ì•ŠëŠ” 30ê°œë¥¼ ìµœì¢… ì„ ì •
        retriever = vectorstore.as_retriever(
            search_type="mmr",
            search_kwargs={'k': 30, 'fetch_k': 100}
        )
        llm = ChatGoogleGenerativeAI(model="gemini-flash-latest", temperature=0)

        # 4. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë° ì²´ì¸ ì„¤ì •
        system_prompt = (
            "ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ëŒ€ì… ì…ì‹œ ìƒë‹´ ì „ë¬¸ AIì…ë‹ˆë‹¤. ì•„ë˜ ì œê³µëœ [ê²€ìƒ‰ëœ ë°ì´í„°]ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì„±ì‹¬ê» ë‹µë³€í•˜ì„¸ìš”.\n\n"
            "[ë‹µë³€ ê·œì¹™]\n"
            "1. **ë°ì´í„° ê¸°ë°˜:** ë°˜ë“œì‹œ ì œê³µëœ ë°ì´í„°ì— ìˆëŠ” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.\n"
            "2. **ìœ ì—°í•œ íƒìƒ‰:** ì‚¬ìš©ìê°€ ë¬¼ì–´ë³¸ ëŒ€í•™ì´ë‚˜ í•™ê³¼ ì´ë¦„ì´ ë°ì´í„°ì— ì™„ë²½íˆ ì¼ì¹˜í•˜ì§€ ì•Šë”ë¼ë„, ê°€ì¥ ìœ ì‚¬í•œ ì •ë³´ë¥¼ ì°¾ì•„ ë‹µë³€ì„ ì‹œë„í•˜ì„¸ìš”. (ì˜ˆ: 'ê°€ì²œëŒ€ ì˜ëŒ€'ë¥¼ ë¬¼ì—ˆëŠ”ë° ë°ì´í„°ì— 'ê°€ì²œëŒ€í•™êµ ì˜ì˜ˆê³¼'ê°€ ìˆë‹¤ë©´ ì´ë¥¼ í™œìš©í•˜ì„¸ìš”.)\n"
            "3. **ìˆ˜ì¹˜ ëª…ì‹œ:** ì ìˆ˜(ì ì •/ì˜ˆìƒ), ëª¨ì§‘ì¸ì›, ì§€ì—­ ë“±ì˜ ì •ë³´ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì–¸ê¸‰í•˜ì„¸ìš”.\n"
            "4. **ë¶€ì¬ ì‹œ ëŒ€ì•ˆ:** ë§Œì•½ ìš”ì²­í•œ í•™ê³¼ì˜ ë°ì´í„°ê°€ ì •ë§ ì—†ë‹¤ë©´, ë™ì¼ ëŒ€í•™ì˜ ìœ ì‚¬ í•™ê³¼ ì •ë³´ë¥¼ ë³´ì—¬ì£¼ë©° ëŒ€ì•ˆì„ ì œì‹œí•˜ëŠ” ë“± ìµœëŒ€í•œ ë„ì›€ì„ ì£¼ì„¸ìš”.\n"
            "5. **ì¹œì ˆí•œ ë§íˆ¬:** ìˆ˜í—˜ìƒì—ê²Œ ë”°ëœ»í•œ ê²©ë ¤ì™€ í•¨ê»˜ ì „ë¬¸ì ì¸ ì¡°ì–¸ì„ ê±´ë„¤ì„¸ìš”.\n\n"
            "[ê²€ìƒ‰ëœ ë°ì´í„°]:\n{context}"
        )

        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("human", "{input}"),
        ])

        # ê²€ìƒ‰-ìƒì„±(RAG) ì²´ì¸ ìƒì„±
        combine_docs_chain = create_stuff_documents_chain(llm, prompt)
        rag_chain = create_retrieval_chain(retriever, combine_docs_chain)

        # 5. ëŒ€í™” ë£¨í”„
        print("\n" + "="*50)
        print("ğŸ“ AI ëŒ€í•™ ì…ì‹œ ì»¨ì„¤í„´íŠ¸ ì±—ë´‡ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”. ì¢…ë£Œí•˜ë ¤ë©´ 'exit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        print("="*50)

        while True:
            user_input = input("\nğŸ‘¤ ì§ˆë¬¸: ").strip()
            
            if user_input.lower() in ["exit", "ì¢…ë£Œ", "quit"]:
                print("ğŸ‘‹ ì…ì‹œ ìƒë‹´ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. í–‰ìš´ì„ ë¹Œì–´ìš”!")
                break
            
            if not user_input:
                continue

            try:
                # [ì§€ëŠ¥í˜• ê²€ìƒ‰] ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— í¬í•¨ëœ ëŒ€í•™êµ ì´ë¦„ ì°¾ê¸°
                # ë‹¨ìˆœíˆ í¬í•¨ ì—¬ë¶€ë§Œ ë³´ëŠ” ê²Œ ì•„ë‹ˆë¼, ì§ˆë¬¸ì—ì„œ ê°€ì¥ ê¸¸ê²Œ ë§¤ì¹­ë˜ëŠ” ëŒ€í•™ ì´ë¦„ì„ ì„ íƒ
                matches = []
                for u in univ_list:
                    u_short = u.replace("ëŒ€í•™êµ", "")
                    if u in user_input:
                        matches.append((u, len(u)))
                    elif len(u_short) >= 2 and u_short in user_input:
                        matches.append((u, len(u_short)))
                
                # ê°€ì¥ ê¸¸ê²Œ ë§¤ì¹­ëœ ëŒ€í•™ì„ ì„ íƒ (ì˜ˆ: 'ì„±ê²°ëŒ€í•™êµ êµ­ì œí•™ê³¼' -> 'êµ­ì œ'ë³´ë‹¤ 'ì„±ê²°ëŒ€í•™êµ' ìš°ì„ )
                search_kwargs = {"k": 30}
                if matches:
                    matches.sort(key=lambda x: x[1], reverse=True)
                    target_univ = matches[0][0]
                    search_kwargs["filter"] = {"univ": target_univ}
                    search_kwargs["k"] = 100
                    print(f"ğŸ¯ '{target_univ}' í•„í„°ë§ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤ (ìµœëŒ€ 100ê°œ)...")
                else:
                    print("ğŸ” ì¼ë°˜ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤...")

                # 1. ë¬¸ì„œ ê²€ìƒ‰
                relevant_docs = vectorstore.similarity_search(user_input, **search_kwargs)
                
                # 2. ê²€ìƒ‰ ê²°ê³¼ ë¡œê·¸ (ì–´ë–¤ ì „ê³µë“¤ì´ ê²€ìƒ‰ë˜ì—ˆëŠ”ì§€ ì¶œë ¥)
                found_majors = sorted(list(set([d.metadata.get('major') for d in relevant_docs])))
                found_univs = sorted(list(set([d.metadata.get('univ') for d in relevant_docs])))
                print(f"âœ… ê²€ìƒ‰ëœ ëŒ€í•™: {found_univs}")
                print(f"âœ… ê²€ìƒ‰ëœ ì „ê³µ(ì¼ë¶€): {found_majors[:10]}... (ì´ {len(found_majors)}ê°œ í•™ê³¼)")

                # 3. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
                doc_contents = [d.page_content for d in relevant_docs]
                context_text = "\n\n".join(doc_contents)
                
                # 4. í”„ë¡¬í”„íŠ¸ ìƒì„± ë° ì‹¤í–‰
                messages = prompt.format_messages(context=context_text, input=user_input)
                response = llm.invoke(messages)
                
                # 5. ë‹µë³€ ì¶œë ¥ (ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì˜ ì‘ë‹µë„ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•˜ë„ë¡ ê°œì„ )
                if isinstance(response.content, list):
                    # ë¦¬ìŠ¤íŠ¸ ë‚´ì˜ ê° í•­ëª©ì—ì„œ 'text' í‚¤ì˜ ê°’ë§Œ í•©ì¹¨
                    final_answer = "".join([part.get("text", "") if isinstance(part, dict) else str(part) for part in response.content])
                else:
                    final_answer = str(response.content)
                
                print(f"\nğŸ¤– AI ë‹µë³€: {final_answer.strip()}")
                
            except Exception as e:
                err_msg = str(e)
                if "429" in err_msg or "RESOURCE_EXHAUSTED" in err_msg.upper():
                    print("\nâš ï¸ API í˜¸ì¶œ í•œë„ ì´ˆê³¼ (429 Error):")
                    print("í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ Gemini APIì˜ ë¬´ë£Œ í‹°ì–´ í• ë‹¹ëŸ‰ì„ ëª¨ë‘ ì†Œì§„í–ˆìŠµë‹ˆë‹¤.")
                    print("ì•½ 1ë¶„~1ì‹œê°„ ë’¤ì— ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜, ë‹¤ë¥¸ API í‚¤ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.")
                else:
                    print(f"\nâŒ ë‹µë³€ ë„ì¤‘ ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {err_msg}")
                print("ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

    except Exception as e:
        print(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    start_chatbot()
